=====TO DO=====
-[1] look at Josh's thesis for anything about induction for use in section 1
-[2] examples of formalizing intuition (closeness topology, rates of change calculus, chance probability)
-[3] examples of limitations see Percy's paper, Kemp et al, grammar induction book
-[4] chaos butterfly? http://www.gocomics.com/tomthedancingbug/
- maybe remove first point of defining structure...a bit off tangent
-[5] examples of importance of reuse in fragment grammar paper
====

MAIN IDEAS
-The process of programming can be a good source of inspiration for modeling cognition
-Learning structured generative concepts
-Modeling abstraction with lambda abstraction
-Future directions
Seen from this perspective, the technology for coping with large-scale computer systems merges with the technology for building new computer languages, and computer science itself becomes no more (and no less) than the discipline of constructing appropriate descriptive languages.
COGNITION AS PROGRAMMING
-quotes from Saussure and SICP
-RL and algorithm design
-chunking as function definition 
-concept learning as lambda abstraction
-language development

STRUCTURED GENERATIVE PROCESSES
-Humans learning can be modeled with structured generative concepts
-Limitations of feature vector representations [3]
-Relations represented as computations
-Number game revisited
  -a possible definition of structure
  -distributions represented as computations with uncertainty

MODELING ABSTRACTION WITH LAMBDA ABSTRACTION
-lambda calculus
-forming lambda abstractions


INITIAL STEPS
-Tree domain 
-Program induction as a computational model of concept learning

PROGRAM INDUCTION 
-Naive Approach 
-Difficulties
-(Re)Using structure [5] 
  -different generative model results

FUTURE DIRECTIONS AND BARRIERS
-Learning grammars as a more general approach
-Grammars in terms of common computations
-Recursion and branching patterns  



-The right definition can lead to powerful results (butterfly effect.. [4]) 
     -Formal methods [2]

